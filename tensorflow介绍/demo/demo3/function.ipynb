{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.W1 = tf.Variable(tf.random.normal([784, 500],stddev=0.03), trainable=True, name='weight_1')\n",
    "        self.B1 = tf.Variable(tf.zeros([500]), trainable=True, name='bias_1')\n",
    "        self.W2 = tf.Variable(tf.random.normal([500, 10],stddev=0.03), trainable=True, name='weight_2')\n",
    "        self.B2 = tf.Variable(tf.zeros([10]), trainable=True, name='bias_2')\n",
    "    \n",
    "    @tf.function   \n",
    "    def call(self, inputs):\n",
    "        layer1 = tf.nn.relu(tf.matmul(inputs, self.W1) + self.B1)\n",
    "        return tf.matmul(layer1, self.W2) + self.B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_mnist(train_X,train_Y):\n",
    "    train_X = tf.reshape(train_X, [-1,784])\n",
    "    train_Y = tf.cast(train_Y, tf.int32)\n",
    "#     train_Y = tf.one_hot(train_Y, 10)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict_labels = model(train_X) \n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=predict_labels, labels=train_Y))\n",
    "    layer_variables = model.trainable_variables\n",
    "    grads = tape.gradient(loss, layer_variables)\n",
    "    optimizer.apply_gradients(zip(grads, layer_variables))\n",
    "    if optimizer.iterations % 100 == 0:\n",
    "#         tf.print(\"grads: \", grads)\n",
    "#         tf.print(\"w1:\", model.W1)\n",
    "#         tf.print(\"w2: \",model.W2)\n",
    "#         tf.print(\"layer_variables: \",layer_variables)\n",
    "        \n",
    "        tf.print(\"After \", optimizer.iterations,end=\"\")\n",
    "        tf.print(\" steps , loss is \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_data(\"mnist.npz\")\n",
    "train,test = mnist\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train).batch(100).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\python\\python3.6.3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1203: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(\"./logs\")\n",
    "tf.summary.trace_on(graph=True, profiler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  100 steps , loss is  0.431293041\n",
      "After  200 steps , loss is  0.448698133\n",
      "After  300 steps , loss is  0.298939824\n",
      "After  400 steps , loss is  0.519782841\n",
      "After  500 steps , loss is  0.183281884\n",
      "After  600 steps , loss is  0.240476325\n",
      "After  700 steps , loss is  0.170609549\n",
      "After  800 steps , loss is  0.142453313\n",
      "After  900 steps , loss is  0.146287337\n",
      "After  1000 steps , loss is  0.222209126\n",
      "After  1100 steps , loss is  0.129638046\n",
      "After  1200 steps , loss is  0.202660814\n",
      "After  1300 steps , loss is  0.0613217503\n",
      "After  1400 steps , loss is  0.112634972\n",
      "After  1500 steps , loss is  0.0857687891\n",
      "After  1600 steps , loss is  0.0970524\n",
      "After  1700 steps , loss is  0.136885345\n",
      "After  1800 steps , loss is  0.201414734\n",
      "After  1900 steps , loss is  0.0429092348\n",
      "After  2000 steps , loss is  0.07485535\n",
      "After  2100 steps , loss is  0.0903446302\n",
      "After  2200 steps , loss is  0.0851831064\n",
      "After  2300 steps , loss is  0.0888379738\n",
      "After  2400 steps , loss is  0.169405043\n",
      "After  2500 steps , loss is  0.0585251413\n",
      "After  2600 steps , loss is  0.0876559466\n",
      "After  2700 steps , loss is  0.0966103524\n",
      "After  2800 steps , loss is  0.0715173557\n",
      "After  2900 steps , loss is  0.062091846\n",
      "After  3000 steps , loss is  0.145184577\n",
      "After  3100 steps , loss is  0.0299972184\n",
      "After  3200 steps , loss is  0.0649803\n",
      "After  3300 steps , loss is  0.0610098094\n",
      "After  3400 steps , loss is  0.0636227354\n",
      "After  3500 steps , loss is  0.0605343729\n",
      "After  3600 steps , loss is  0.119227074\n",
      "After  3700 steps , loss is  0.0283205342\n",
      "After  3800 steps , loss is  0.0630596\n",
      "After  3900 steps , loss is  0.0511144847\n",
      "After  4000 steps , loss is  0.0739714503\n",
      "After  4100 steps , loss is  0.0424309112\n",
      "After  4200 steps , loss is  0.0826183483\n",
      "After  4300 steps , loss is  0.0381368175\n",
      "After  4400 steps , loss is  0.04307108\n",
      "After  4500 steps , loss is  0.0462572947\n",
      "After  4600 steps , loss is  0.0669474229\n",
      "After  4700 steps , loss is  0.0606539734\n",
      "After  4800 steps , loss is  0.053123679\n",
      "After  4900 steps , loss is  0.037278343\n",
      "After  5000 steps , loss is  0.0511820354\n",
      "After  5100 steps , loss is  0.0373762436\n",
      "After  5200 steps , loss is  0.0539297163\n",
      "After  5300 steps , loss is  0.0350913629\n",
      "After  5400 steps , loss is  0.0334892049\n",
      "After  5500 steps , loss is  0.0273549668\n",
      "After  5600 steps , loss is  0.00781061\n",
      "After  5700 steps , loss is  0.021799976\n",
      "After  5800 steps , loss is  0.0187129155\n",
      "After  5900 steps , loss is  0.0424606167\n",
      "After  6000 steps , loss is  0.0241462737\n"
     ]
    }
   ],
   "source": [
    "for train_X, train_Y in train_ds:\n",
    "    if optimizer.iterations > 6000:\n",
    "        break\n",
    "    train_mnist(tf.cast(train_X,tf.float32), train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\python\\python3.6.3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1259: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From g:\\python\\python3.6.3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1259: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "WARNING:tensorflow:From g:\\python\\python3.6.3\\lib\\site-packages\\tensorflow\\python\\eager\\profiler.py:151: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    }
   ],
   "source": [
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"my_func_trace\",\n",
    "        step=0,\n",
    "        profiler_outdir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  tf.Tensor(0.9587, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_X, test_Y = test\n",
    "test_X = tf.cast(tf.reshape(test_X,[-1, 784]), tf.float32)\n",
    "test_predict = model(test_X)\n",
    "correct_prediction = tf.equal(test_Y, tf.argmax(test_predict, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
